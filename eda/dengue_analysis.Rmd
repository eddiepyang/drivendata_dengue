---
title: "Dengue EDA"
output:
  html_document:
    df_print: paged
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 
# Loading packages

```{r, echo = FALSE}

# data mainpulation
library(dplyr)
library(purrr)
library(data.table)
library(zoo)
library(lubridate)

# charts
library(ggthemes)
library(ggplot2)

# ts
library(zoo)
library(lubridate)
library(forecast)


```


```{r}
response <- fread('../input/dengue_labels_train.csv')
dengue <- fread('../input/dengue_features_train.csv')
str(dengue)

```

```{r}

cor_table <- select(dengue, 5:ncol(dengue)) %>% 
  cor(use = 'pairwise.complete.obs')

corrplot::corrplot(cor_table)  
# ?apply
# cor_table[table(apply(cor_table, 2, function(x) x >.5))]

#apply(cor_table, 2, function(x) x >.5)


```

## Combining independent and dependent

```{r}

#glm.fit(dengue[,5:ncol(dengue)], response$total_cases, family = poisson())

combined_data <- left_join(dengue, response) 

# fills na values
combined_data2 <- map_df(combined_data, na.locf)
combined_data2$week_start_date <- ymd(combined_data2$week_start_date)

# check
colSums(is.na(combined_data))

summary(combined_data)
dim(response)
dim(dengue)

```


```{r}

 
  ggplot(combined_data2, aes(x = week_start_date, y = total_cases, color = city)) + 
  geom_line()
```

# ARIMA fit 

```{r}

sj_series <- ts(combined_data2[combined_data2$city == 'sj',]$total_cases, 
                start = c(1990, 18), frequency = 52)

sj_fit <- auto.arima(sj_series)
summary(sj_fit)
checkresiduals(sj_fit)

# test forecasts, arma is p, q, P, Q, M, d, D

sj_fit$arma
cv_forecast <- function (x, h) forecast(Arima(x, order = c(1,1,1)), h = 1)
error_vector <- tsCV(sj_series, cv_forecast, h = 1)
```

## Inspecting differences by city

```{r}

stacked_hist <- function(data, ind_var, factor_var, filter_dates = TRUE)
{
  if (filter_dates == TRUE) 
    {
    data = filter(data, week_start_date >= '2000-01-01', week_start_date <= '2008-12-30')
    ggplot(data, aes_string(x = ind_var)) +
    geom_histogram(aes_string(y= "..count../sum(..count..)", fill = factor_var, color = "'black'"), bins =     60) +
    # geom_histogram(aes_string(fill = factor_var, color = "'black'"), bins = 60) +
    guides(color = FALSE) +
    ylab('proportion') +
    theme_hc()
  }
}

stacked_hist(combined_data2, "total_cases", "city")

stacked_hist(dengue, "precipitation_amt_mm", "city")

stacked_hist(dengue, "station_avg_temp_c", "city")
```

Skewed right, and cases are integers so a poisson or negative binomial may be appropriate. In poisson the mean == variance, we can check that for these distributions.

```{r}
group_by(response, city) %>%
  summarise(mean(total_cases), var(total_cases))

library(fitdistrplus)

filter(response, city == 'sj') %>%
  .$total_cases %>% 
  as.numeric() %>%
  descdist(discrete = TRUE)
```


## Summary stats by city

```{r}

group_by(response, city, year) %>%
  summarize(sum(total_cases), mean(total_cases), n(), max(total_cases), min(total_cases))

```



```{r}
# medians <- apply(combined_data, 2, function(x) median(as.numeric(x), na.rm = TRUE))
# 
# replace_na <- function(vect, median) {
#   ifelse(is.na(vect), median, vect)
# }
# 
# replace_na(c(1,2,3,NA), 2)
# 
# for (item in medians) {
#   if(!is.na(item)) {
#     print(item)
#   }
# }


# combined_data2 <- na.aggregate(combined_data, by = 'year', FUN = function(x) median(x, na.rm = TRUE))
# 
# combined_data2 <- apply(combined_data2[,5:ncol(combined_data2)], 2, as.numeric) %>% 
#   as.data.frame() %>%
#   cbind(combined_data2[,1:4], .)

# separate cities, otherwise indices are not unique
# spread(combined_data, city, total_cases) %>% 
#   zoo(., order.by = .$week_start_date) %>% 
#   na.aggregate(format, "%Y") %>% 
#   is.na() %>% 
#   colSums()

filter(combined_data, city == 'iq') %>%
  dplyr::select(week_start_date) %>% dim()

```

## Negative binomial glm 

```{r}

# Baseline model for analysis, no data splitting done
nb_1 <- glm.nb(total_cases ~ ., combined_data2)

summary(nb_1)

# glmnet

library(glmnet)

# returns lambda value for lowest cv mse

combined_data2$city <- combined_data2$city %>%
  as.factor()

cv_elas1 <- cv.glmnet(dplyr::select(combined_data2, -total_cases) %>% data.matrix(), 
                dplyr::select(combined_data2, total_cases)[,1] %>% unlist%>% as.numeric(), family = 'poisson', 
                alpha = .5)
summary(cv_elas1)


```

## Caret

```{r}

library(caret)

combined_data_dummied <- dummyVars(total_cases~., data = combined_data2)
head(predict(combined_data_dummied, newdata = combined_data2))

# find linear combos to avoid multicoll

remove_cols <- findLinearCombos(data.matrix(combined_data2))$remove

combined_data2 <- combined_data2[-remove_cols]
idx <- createDataPartition(y = combined_data2$total_cases, p = .6, list = FALSE)
train <- combined_data2[idx,]
test <- combined_data2[-idx,]


combined_processed <- preProcess(combined_data2, method = c('pca'))

combined_processed


```
